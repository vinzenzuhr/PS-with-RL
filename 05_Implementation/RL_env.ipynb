{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "600e7dfa-0283-46dc-92fb-f3f4c36fff43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-14 21:02:33.329305: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-14 21:02:33.491608: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-14 21:02:33.491666: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-14 21:02:33.491717: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-14 21:02:33.521300: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-14 21:02:33.523557: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-14 21:02:36.999402: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "import os\n",
    "\n",
    "import torch \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from custom_modules import Training, DataGenerator, GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d4338b3-e039-4a95-a15e-e4828e237fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    output_dir = \"RL_PersSched\"\n",
    "    num_epoch = 1000000 #10'000 needs 1 hour with 3x CPU, 3GB RAM and 1x 1080ti\n",
    "    max_steps = 28\n",
    "    batch_size = 1280\n",
    "    replay_size = 1280\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    eval_every_n_epochs = 2000\n",
    "    lr = 1e-4\n",
    "    gamma = 0.99\n",
    "    hidden_dim = 32\n",
    "    num_message_layer = 2\n",
    "    clip_norm = 1\n",
    "\n",
    "config = TrainingConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd5a1ff-2334-4015-af1e-fc20e3770734",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34866725-a019-416a-88c7-2146df8b8ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_summary = SummaryWriter(config.output_dir, purge_step=0)\n",
    "os.makedirs(config.output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a2c7477-436d-4954-a4e9-e32a27dfa6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_employee = 1\n",
    "dim_shift = 7\n",
    "gnn = GNN((dim_employee, dim_shift), hidden_dim=config.hidden_dim, num_message_layer=config.num_message_layer, device=config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ca3d151-b5ca-4742-bd82-e3a73a73f379",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    gnn.parameters(), \n",
    "    lr=config.lr, \n",
    "    amsgrad=True\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c18de9db-63af-46f4-9be0-befea097320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_summary.add_scalar(\"num_parameters\", len(gnn.parameters()), 0)\n",
    "tb_summary.add_scalar(\"num_epoch\", config.num_epoch, 0)\n",
    "tb_summary.add_scalar(\"max_steps\", config.max_steps, 0)\n",
    "tb_summary.add_scalar(\"batch_size\", config.batch_size, 0)\n",
    "tb_summary.add_scalar(\"replay_size\", config.replay_size, 0)\n",
    "tb_summary.add_scalar(\"eval_every_n_epochs\", config.eval_every_n_epochs, 0)\n",
    "tb_summary.add_scalar(\"lr\", config.lr, 0)\n",
    "tb_summary.add_scalar(\"gamma\", config.gamma, 0)\n",
    "tb_summary.add_scalar(\"hidden_dim\", config.hidden_dim, 0)\n",
    "tb_summary.add_scalar(\"num_message_passing\", config.num_message_layer, 0)\n",
    "tb_summary.add_scalar(\"clip_norm\", config.clip_norm, 0)\n",
    "tb_summary.add_scalar(\"num_shifts\", DataGenerator.get_week_shifts().shape[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03972eab-f5f3-4e86-b277-0635e330b13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153e998e740c478fbe67e733eddc56f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m\n\u001b[1;32m      1\u001b[0m training \u001b[38;5;241m=\u001b[39m Training(\n\u001b[1;32m      2\u001b[0m     gnn, \n\u001b[1;32m      3\u001b[0m     optimizer, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     clip_norm\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mclip_norm\n\u001b[1;32m     14\u001b[0m ) \n\u001b[0;32m---> 15\u001b[0m \u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workdir/BFH/custom_modules/Training.py:189\u001b[0m, in \u001b[0;36mTraining.start_training\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39menv \u001b[38;5;241m=\u001b[39m env \n\u001b[1;32m    188\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor\u001b[38;5;241m.\u001b[39msample_episode() \n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gradient_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_every_n_epochs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation()\n",
      "File \u001b[0;32m~/workdir/BFH/custom_modules/Training.py:125\u001b[0m, in \u001b[0;36mTraining._gradient_update\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m objective \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mlog_probs \u001b[38;5;241m*\u001b[39m future_returns_batch)\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad() \n\u001b[0;32m--> 125\u001b[0m \u001b[43mobjective\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_norm \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    128\u001b[0m     gnn_gradient_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgnn\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_norm)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training = Training(\n",
    "    gnn, \n",
    "    optimizer, \n",
    "    tb_summary, \n",
    "    device=config.device,  \n",
    "    gamma=config.gamma,\n",
    "    max_steps=config.max_steps, \n",
    "    num_epoch=config.num_epoch, \n",
    "    batch_size=config.batch_size, \n",
    "    replay_size=config.replay_size, \n",
    "    eval_every_n_epochs=config.eval_every_n_epochs,\n",
    "    output_dir=config.output_dir,\n",
    "    clip_norm=config.clip_norm\n",
    ") \n",
    "training.start_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbef0127-26f7-4177-9d57-854b71a1b2da",
   "metadata": {},
   "source": [
    "## Save as python script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "211f4f10-9fd8-43c6-aff2-6a98a473affb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook RL_env.ipynb to script\n",
      "[NbConvertApp] Writing 2632 bytes to RL_env.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "!jupyter nbconvert --to script \"RL_env.ipynb\"\n",
    "filename = \"RL_env.py\"\n",
    "\n",
    "# delete this cell from python file\n",
    "lines = []\n",
    "with open(filename, 'r') as fp:\n",
    "    lines = fp.readlines()\n",
    "with open(filename, 'w') as fp:\n",
    "    for number, line in enumerate(lines):\n",
    "        if number < len(lines)-17: \n",
    "            fp.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
